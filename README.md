# ğŸ³ InstaDish - AI-Powered Recipe Discovery

A modern, AI-powered recipe discovery platform built with FastAPI and React, featuring semantic search, sustainability analysis, and intelligent chatbot assistance.

## âœ¨ Features

- **ğŸ” Semantic Recipe Search**: Find recipes using natural language queries powered by FAISS vector search
- **ğŸ¤– AI Chatbot**: Get cooking advice and recipe suggestions from an AI assistant
- **ğŸŒ± Sustainability Analysis**: Analyze the environmental impact of your ingredients
- **ğŸ“Š Recipe Matching**: See how well your ingredients match recipe requirements
- **ğŸ’¾ Persistent Embeddings**: Fast startup with cached vector embeddings
- **ğŸ“± Responsive Design**: Beautiful, mobile-friendly interface

## ğŸ—ï¸ Architecture

- **Backend**: FastAPI with Python 3.9+
- **Frontend**: React with TypeScript
- **AI/ML**: FAISS, sentence-transformers, Ollama
- **Data**: 1,339 real recipes from CSV database
- **Environment**: Conda for Python dependency management

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 16+
- Conda/Miniconda
- Ollama (for AI chatbot)

### 1. Setup Backend

```bash
# Activate conda environment
conda activate instadish

# Install Python dependencies
cd backend
pip install -r requirements.txt

# Start the backend
cd ..
./start_backend.sh
```

The backend will be available at `http://localhost:8000`

### 2. Setup Frontend

```bash
# Install Node.js dependencies
cd frontend
npm install

# Start the frontend
npm start
```

The frontend will be available at `http://localhost:3000`

### 3. Setup AI Chatbot (Optional)

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull the model
ollama pull llama2:7b

# Start Ollama service
ollama serve
```

## ğŸ“ Project Structure

```
InstaDish/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Main application
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â”œâ”€â”€ rag_service.py  # FAISS + embeddings
â”‚   â”‚   â”œâ”€â”€ ollama_service.py # AI chatbot
â”‚   â”‚   â””â”€â”€ sustainability_service.py
â”‚   â”œâ”€â”€ data/               # Persistent embeddings
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/               # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # UI components
â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom React hooks
â”‚   â”‚   â””â”€â”€ services/      # API service layer
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ recipes_small.csv       # Recipe database
â”œâ”€â”€ start_backend.sh        # Backend startup script
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

### Recipes
- `GET /api/recipes` - Get all recipes
- `GET /api/recipes/{id}` - Get specific recipe
- `POST /api/recipes/search` - Search recipes
- `GET /api/recipes/categories` - Get categories

### Chatbot
- `POST /api/chatbot` - Chat with AI
- `GET /api/chatbot/status` - Check chatbot status
- `POST /api/chatbot/quick-questions` - Get quick questions

### Sustainability
- `POST /api/sustainability/analyze` - Analyze ingredients

### Health
- `GET /health` - Health check

## ğŸŒ± Sustainability Analysis

The app analyzes ingredients for:
- **Carbon Footprint**: COâ‚‚ emissions per ingredient
- **Water Usage**: Water consumption per ingredient
- **Sustainability Score**: Overall environmental impact
- **Recommendations**: Tips for more sustainable cooking

## ğŸ¤– AI Features

- **Semantic Search**: Find recipes using natural language
- **Contextual Responses**: AI responses include relevant recipe suggestions
- **Ingredient Matching**: Smart matching of available ingredients
- **Cooking Advice**: Get tips and substitutions from the AI

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend
python -m uvicorn main:app --reload
```

### Frontend Development

```bash
cd frontend
npm start
```

### Adding New Recipes

1. Add recipes to `recipes_small.csv`
2. Restart the backend to regenerate embeddings
3. New recipes will be automatically indexed

## ğŸ“Š Performance

- **Vector Search**: Sub-second recipe search with FAISS
- **Cached Embeddings**: Fast startup with persistent storage
- **Batch Processing**: Efficient embedding generation
- **Responsive UI**: Smooth user experience

## ğŸ”’ Environment Variables

Create a `.env` file in the backend directory:

```env
# Optional: Custom Ollama URL
OLLAMA_BASE_URL=http://localhost:11434

# Optional: Custom model
OLLAMA_MODEL=llama2:7b
```

## ğŸ› Troubleshooting

### Backend Issues
- Ensure conda environment is activated
- Check that all dependencies are installed
- Verify CSV file exists in project root

### Frontend Issues
- Clear browser cache
- Check that backend is running on port 8000
- Verify CORS settings

### AI Chatbot Issues
- Ensure Ollama is running
- Check that llama2:7b model is installed
- Verify Ollama service is accessible

## ğŸ“ License

MIT License - feel free to use this project for learning and development!

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ™ Acknowledgments

- Recipe data from various sources
- FAISS for vector search
- Ollama for AI capabilities
- FastAPI and React communities